{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all Libraries \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "from numpy import * \n",
    "\n",
    "import scipy.io.wavfile as wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython import embed\n",
    "import ipdb\n",
    "\n",
    "import theano\n",
    "import theano.tensor as Th\n",
    "from lasagne.layers  import InputLayer, DenseLayer, DropoutLayer, ElemwiseSumLayer,LSTMLayer,ReshapeLayer\n",
    "from lasagne.layers import SliceLayer, get_output, get_all_params\n",
    "from lasagne.updates import adam\n",
    "import downhill\n",
    "\n",
    "eps = finfo( float32).eps;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a TIMIT data set\n",
    "def tset( mf = None, ff = None, dr = None):\n",
    "    # Where the files are\n",
    "    p = '/Users/avinana/Paris Independent Study/timit-wav/train/';\n",
    "\n",
    "    # Pick a speaker directory\n",
    "    if dr is None:\n",
    "        dr = random.randint( 1, 8)\n",
    "    p += 'dr%d/' % dr\n",
    "\n",
    "    # Get two random speakers\n",
    "    if mf is None:\n",
    "        mf = [name for name in os.listdir( p) if name[0] == 'm']\n",
    "        mf = random.choice( mf)\n",
    "    if ff is None:\n",
    "        ff = [name for name in os.listdir( p) if name[0] == 'f']\n",
    "        ff = random.choice( ff)\n",
    "    print ('dr%d/' % dr), mf, ff\n",
    "\n",
    "    # Load all the wav files\n",
    "    ms = [wavfile.read(p+mf+'/'+n)[1] for n in os.listdir( p+mf) if 'wav' in n]\n",
    "    fs = [wavfile.read(p+ff+'/'+n)[1] for n in os.listdir( p+ff) if 'wav' in n]\n",
    "\n",
    "    # Find suitable test file pair\n",
    "    l1 = map( lambda x : x.shape[0], ms)\n",
    "    l2 = map( lambda x : x.shape[0], fs)\n",
    "    d = array( [[abs(t1-t2) for t1 in l1] for t2 in l2])\n",
    "    i = argmin( d)\n",
    "    l = max( [l1[i%10], l2[i/10]])\n",
    "    ts = [pad( ms[i%10], (0,l-l1[i%10]), 'constant'), pad( fs[i/10], (0,l-l2[i/10]), 'constant')]\n",
    "\n",
    "    # Get training data\n",
    "    ms.pop( i%10)\n",
    "    fs.pop( i/10)\n",
    "    tr = [concatenate(ms), concatenate(fs)]\n",
    "\n",
    "    return map( lambda x : (x-mean(x))/std(x), ts), map( lambda x : (x-mean(x))/std(x), tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (make it a function, with the choice of TIMIT and mock data)\n",
    "\n",
    "def sound_set( tp):\n",
    "    import scipy.io.wavfile as wavfile\n",
    "#     import paris.speech\n",
    "\n",
    "    # Two sinusoids signal\n",
    "    if tp == 1:\n",
    "        l = 8*1024\n",
    "        sr = 8000\n",
    "        def clip0( x):\n",
    "            return x * (x>0)\n",
    "        z1 = clip0( sin( 3*linspace( 0, 2*pi, l))) * sin( 1099*linspace( 0, 2*pi, l))\n",
    "        z2 = clip0( sin( 2*linspace( 0, 2*pi, l))) * sin( 3222*linspace( 0, 2*pi, l))\n",
    "        z3 = clip0( sin( 5*linspace( 0, 2*pi, l))) * sin( 1099*linspace( 0, 2*pi, l))\n",
    "        z4 = clip0( sin( 3*linspace( 0, 2*pi, l))) * sin( 3222*linspace( 0, 2*pi, l))\n",
    "\n",
    "        z1 = hstack( (zeros(l/8),z1))\n",
    "        z2 = hstack( (zeros(l/8),z2))\n",
    "        z3 = hstack( (zeros(l/8),z3))\n",
    "        z4 = hstack( (zeros(l/8),z4))\n",
    "\n",
    "    \n",
    "    # TIMIT male/female set\n",
    "    elif tp == 2:\n",
    "        #ts,tr = tset( 'fpad0', 'mbma1', 6)\n",
    "        ts,tr = tset()\n",
    "        sr = 16000\n",
    "\n",
    "        tr[0] = tr[0][:min(tr[0].shape[0],tr[1].shape[0])]\n",
    "        tr[1] = tr[1][:min(tr[0].shape[0],tr[1].shape[0])]\n",
    "\n",
    "        z1 = tr[1] / std( tr[1])\n",
    "        z2 = tr[0] / std( tr[0])\n",
    "        z3 = ts[1] / std( ts[1])\n",
    "        z4 = ts[0] / std( ts[0])\n",
    "\n",
    "    # Pad them\n",
    "    sz = 1024\n",
    "\n",
    "    def zp( x):\n",
    "        return hstack( (zeros(sz),x[:int(sz*floor(x.shape[0]/sz))],zeros(sz)))\n",
    "\n",
    "    tr1 = zp( z1[:int(sz*floor(z1.shape[0]/sz))])\n",
    "    tr2 = zp( z2[:int(sz*floor(z2.shape[0]/sz))])\n",
    "    ts1 = zp( z3[:int(sz*floor(z3.shape[0]/sz))])\n",
    "    ts2 = zp( z4[:int(sz*floor(z4.shape[0]/sz))])\n",
    "\n",
    "    # Show me\n",
    "    #soundsc( ts1+ts2, sr)\n",
    "\n",
    "    return tr1,tr2,ts1,ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Class to extract sound features (STFT)\n",
    "# Input : sz : Size\n",
    "#         hp : hop size \n",
    "#         wn : window function \n",
    "########################################\n",
    "\n",
    "class sound_feats:\n",
    "\n",
    "    # Initializer\n",
    "    def __init__(self, sz, hp, wn):\n",
    "        import scipy.fftpack\n",
    "\n",
    "        self.sz = sz\n",
    "        self.hp = hp\n",
    "        self.wn = wn\n",
    "\n",
    "        # Forward transform definition\n",
    "        self.F = scipy.fftpack.fft( identity( self.sz))\n",
    "\n",
    "        # Inverse transform with a window\n",
    "        self.iF = conj( self.wn * self.F.T)\n",
    "\n",
    "    # Modulator definition\n",
    "    def md( self, x):\n",
    "        return abs( x)+eps\n",
    "\n",
    "    # Buffer with overlap\n",
    "    def buffer( self, s):\n",
    "        return array( [s[i:i+self.sz] for i in arange( 0, len(s)-self.sz+1, self.hp)]).T\n",
    "\n",
    "    # Define overlap add matrix\n",
    "    def oam( self, n):\n",
    "        import scipy.sparse\n",
    "        ii = array( [i*self.hp+arange( self.sz) for i in arange( n)]).flatten()\n",
    "        jj = array( [i*self.sz+arange( self.sz) for i in arange( n)]).flatten()\n",
    "        return scipy.sparse.coo_matrix( (ones( len( ii)), (ii,jj)) ).tocsr()\n",
    "\n",
    "    # Front end\n",
    "    def fe( self, s):\n",
    "        C = self.F.dot( self.wn*self.buffer( s))[:self.sz/2+1,:]\n",
    "        M = self.md( C)\n",
    "        P = C / M\n",
    "        return (M,P)\n",
    "\n",
    "    # Inverse transform\n",
    "    def ife( self, M, P):\n",
    "        oa = self.oam( M.shape[1])\n",
    "        f = vstack( (M*P,conj(M*P)[-2:0:-1,:]))\n",
    "        return oa.dot( reshape( real( self.iF.dot( f)), (-1,1), order='F')).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Blind Source seperation evaluation\n",
    "##################\n",
    "from numpy import *\n",
    "\n",
    "# SDR, SIR, SAR estimation\n",
    "def bss_eval( sep, i, sources):\n",
    "    # Current target\n",
    "    target = sources[i]\n",
    "    \n",
    "    # Target contribution\n",
    "    s_target = target * dot( target, sep.T) / dot( target, target.T)\n",
    "\n",
    "    # Interference contribution\n",
    "    pse = dot( dot( sources, sep.T),linalg.inv( dot( sources, sources.T))).T.dot( sources)\n",
    "    e_interf = pse - s_target\n",
    "    \n",
    "    # Artifact contribution\n",
    "    e_artif= sep - pse;\n",
    "    \n",
    "    # Interference + artifacts contribution\n",
    "    e_total = e_interf + e_artif;\n",
    "    \n",
    "    # Computation of the log energy ratios\n",
    "    sdr = 10*log10( sum( s_target**2) / sum( e_total**2));\n",
    "    sir = 10*log10( sum( s_target**2) / sum( e_interf**2));\n",
    "    sar = 10*log10( sum( (s_target + e_interf)**2) / sum( e_artif**2));\n",
    "    \n",
    "    # Done!\n",
    "    return (sdr, sir, sar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Define a training loop \n",
    "########################\n",
    "\n",
    "def downhill_train( opt, train, hh, ep, pl):\n",
    "    cst = []\n",
    "    st = time.time()\n",
    "    lt = st\n",
    "    try:\n",
    "        for tm,_ in opt.iterate( train, learning_rate=hh, max_updates=ep, patience=ep, min_improvement=0):\n",
    "            cst.append( tm['loss'])\n",
    "            if time.time() - lt > 4 :\n",
    "                nt = time.time()\n",
    "                epc = len( cst)\n",
    "                plt.clf()\n",
    "                plt.plot(cst)\n",
    "    #             plt.semilogy( cst)\n",
    "                plt.title( 'Cost: %.1e  Speed: %.2f ep/s  Time: %.1f/%.1f' %(cst[-1], epc/(nt-st), nt-st, ep/(epc/(nt-st))) )\n",
    "                plt.ylabel( 'Cost')\n",
    "                IPython.display.clear_output(wait = True)\n",
    "                plt.show()\n",
    "                lt = time.time()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    return cst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Neural net : Define the lasagne seperation neural net\n",
    "\n",
    "#########################################################\n",
    "# %debug\n",
    "def psoftplus( x, p = 1.):\n",
    "    return Th.switch( x < -30./p, 0., Th.switch( x > 30./p, x, Th.log1p( Th.exp( p*x))/p))\n",
    "\n",
    "\n",
    "# Get a Lasagne layer output\n",
    "def nget( x, s, y):\n",
    "    return theano.function( [s], squeeze( get_output( x, deterministic=True)))( y)\n",
    "\n",
    "# Learn models using a Lasagne network\n",
    "def lasagne_models( M, P, FE, z, K = 20, hh = .0001, ep = 5000, d = 0, wsp = 0.0001, plt = True):\n",
    "    \n",
    "    # Copy key variables to GPU\n",
    "    _M = Th.matrix( '_M')\n",
    "\n",
    "    # Input and forward transform\n",
    "    I = InputLayer( shape=M.T.shape, input_var=_M)\n",
    "\n",
    "    # First layer is the transform to a non-negative subspace\n",
    "    H0  = DenseLayer( I, num_units=K, nonlinearity=lambda x: psoftplus( x, 3.), b=None)\n",
    "\n",
    "    # Optional dropout\n",
    "    H = DropoutLayer( H0, d)\n",
    "\n",
    "    # Compute source modulator\n",
    "    R  = DenseLayer( H, num_units=M.T.shape[1], nonlinearity=lambda x: psoftplus( x, 3.), b=None)\n",
    "\n",
    "    # Cost function\n",
    "    cost = (_M*(Th.log(_M+eps) - Th.log( get_output( R)+eps)) - _M + get_output( R)).mean() \\\n",
    "       + wsp*Th.mean( abs( R.W))\n",
    "\n",
    "    # Train it using Lasagne\n",
    "    opt = downhill.build( 'rprop', loss=cost, inputs=[_M], params=get_all_params( R))\n",
    "    train = downhill.Dataset( M.T.astype(float32), batch_size=0)\n",
    "    er = downhill_train( opt, train, hh, ep, None)[-1]\n",
    "    #er = train_loop( opt, train, hh, ep, None)[-1]\n",
    "    # Get approximation\n",
    "    _r = nget( R, _M, M.T.astype( float32)).T\n",
    "    _h = nget( H, _M, M.T.astype( float32)).T\n",
    "    o = FE.ife( _r, P)\n",
    "    sxr = bss_eval( o, 0, array([z]))\n",
    "\n",
    "    return R ,sxr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasagne_separate2( M, P, FE, W1, W2, z1, z2, hh = .0001, ep = 5000, d = 0, wsp =.0001, plt = True):\n",
    "\n",
    "    # Gt dictionary shapes\n",
    "    K = [W1.shape[0],W2.shape[0]]\n",
    "\n",
    "    # GPU cached data\n",
    "    _M = theano.shared( M.T.astype( float32))\n",
    "    dum = Th.vector( 'dum')\n",
    "\n",
    "    # We have weights to discover\n",
    "    H = theano.shared( random.rand( M.T.shape[0],K[0]+K[1]).astype( float32))\n",
    "    fI = InputLayer( shape=(M.T.shape[0],K[0]+K[1]), input_var=H)\n",
    "\n",
    "    # Split in two pathways\n",
    "    fW1 = SliceLayer( fI, indices=slice(0,K[0]), axis=1)\n",
    "    fW2 = SliceLayer( fI, indices=slice(K[0],K[0]+K[1]), axis=1)\n",
    "\n",
    "    # Dropout?\n",
    "    dfW1 = DropoutLayer( fW1, d)\n",
    "    dfW2 = DropoutLayer( fW2, d)\n",
    "\n",
    "    # Compute source modulators using previously learned dictionaries\n",
    "    R1  = DenseLayer( dfW1, num_units=M.shape[0], W=W1.astype( float32),\n",
    "      nonlinearity=lambda x: psoftplus( x, 3.), b=None)\n",
    "    R2  = DenseLayer( dfW2, num_units=M.shape[0], W=W2.astype( float32),\n",
    "      nonlinearity=lambda x: psoftplus( x, 3.), b=None)\n",
    "\n",
    "    # Add the two approximations\n",
    "    R = ElemwiseSumLayer( [R1, R2])\n",
    "\n",
    "    # Cost function\n",
    "    cost = (_M*(Th.log(_M+eps) - Th.log( get_output( R)+eps)) - _M + get_output( R)).mean() \\\n",
    "       + wsp*Th.mean( H) + 0*Th.mean( dum)\n",
    "\n",
    "    # Train it using Lasagne\n",
    "    opt = downhill.build( 'rprop', loss=cost, inputs=[dum], params=[H])\n",
    "    train = downhill.Dataset( _M, batch_size=0)\n",
    "    er = downhill_train( opt, train, hh, ep, None)[-1]\n",
    "\n",
    "    # Get outputs\n",
    "    _r  = nget( R,  dum, array( [0]).astype(float32)) + eps\n",
    "    _r1 = nget( R1, dum, array( [0]).astype(float32))\n",
    "    _r2 = nget( R2, dum, array( [0]).astype(float32))\n",
    "    o1 = FE.ife( _r1 * (M/_r), P)\n",
    "    o2 = FE.ife( _r2 * (M/_r), P)\n",
    "    sxr = bss_eval( o1, 0, vstack( (z1,z2))) + bss_eval( o2, 1, vstack( (z1,z2)))\n",
    "\n",
    "    return o1,o2,(array(sxr[:3]) + array(sxr[3:]))/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasagne_separate( M, P, FE, W1, W2, z1, z2, hh = .0001, ep = 5000, d = 0, wsp =.0001, plt = True):\n",
    "\n",
    "    # Gt dictionary shapes\n",
    "    K = [W1.shape[0],W2.shape[0]]\n",
    "\n",
    "    # GPU cached data\n",
    "    _M = theano.shared( M.astype( float32))\n",
    "\n",
    "    # Input is the learned dictionary set\n",
    "    lW = hstack( (W1.T,W2.T)).astype( float32)\n",
    "    _lW  = Th.matrix( '_lW');\n",
    "    fI = InputLayer( shape=lW.shape, input_var=_lW)\n",
    "\n",
    "    # Split in two paths\n",
    "    fW1 = SliceLayer( fI, indices=slice(0,K[0]), axis=1)\n",
    "    fW2 = SliceLayer( fI, indices=slice(K[0],K[0]+K[1]), axis=1)\n",
    "\n",
    "    # Dropout?\n",
    "    dfW1 = DropoutLayer( fW1, d)\n",
    "    dfW2 = DropoutLayer( fW2, d)\n",
    "\n",
    "    # Compute source modulators\n",
    "    R1  = DenseLayer( dfW1, num_units=M.shape[1], nonlinearity=lambda x: psoftplus( x, 3.), b=None)\n",
    "    R2  = DenseLayer( dfW2, num_units=M.shape[1], nonlinearity=lambda x: psoftplus( x, 3.), b=None)\n",
    "\n",
    "    # Bring to standard orientation\n",
    "    R = ElemwiseSumLayer( [R1, R2])\n",
    "\n",
    "    # Cost function\n",
    "    cost = (_M*(Th.log(_M+eps) - Th.log( get_output( R)+eps)) - _M + get_output( R)).mean() \\\n",
    "       + wsp*(Th.mean( abs( R1.W))+Th.mean( abs( R2.W)))\n",
    "\n",
    "    # Train it using Lasagne\n",
    "    opt = downhill.build( 'rprop', loss=cost, inputs=[_lW], params=get_all_params( R))\n",
    "    train = downhill.Dataset( lW, batch_size=0)\n",
    "    er = downhill_train( opt, train, hh, ep, None)[-1]\n",
    "\n",
    "    # Get outputs\n",
    "    _r  = nget( R,  _lW, lW) + eps\n",
    "    _r1 = nget( R1, _lW, lW)\n",
    "    _r2 = nget( R2, _lW, lW)\n",
    "    o1 = FE.ife( _r1 * (M/_r), P)\n",
    "    o2 = FE.ife( _r2 * (M/_r), P)\n",
    "    sxr = bss_eval( o1, 0, vstack( (z1,z2))) + bss_eval( o2, 1, vstack( (z1,z2)))\n",
    "\n",
    "    return o1,o2,(array(sxr[:3]) + array(sxr[3:]))/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sound set\n",
    "# %debug\n",
    "\n",
    "random.seed( 0)\n",
    "Z = sound_set(2)\n",
    "\n",
    "sz = 1024\n",
    "hp = 256\n",
    "# Front-end details\n",
    "if hp is None:\n",
    "    hp = sz/4\n",
    "wn = reshape( hanning(sz+1)[:-1], (sz,1))**.5\n",
    "FE = sound_feats(sz,hp,wn)\n",
    "M1,P1 = FE.fe( Z[0])\n",
    "n1,c1 = lasagne_models( M1, P1, FE, Z[0],20, .001, 1000, 0.25, .0001, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2,P2 = FE.fe( Z[1])\n",
    "n2,c2 = lasagne_models( M2, P2, FE, Z[1], 20, .01, 1000, 0.25, .0001, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,P = FE.fe( Z[2]+Z[3])\n",
    "o1,o2,sxr = lasagne_separate( M, P, FE, n1.W.get_value(), n2.W.get_value(),Z[2], Z[3], .0001, 2000, 0, 0.01, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}